{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCxQyK2g_2Jj"
      },
      "source": [
        "# Lab 2 AI for Multimodal Cyberharassment Detection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9ZCA9FpFasW"
      },
      "source": [
        "With previous lab learning, you should have some knowledge about how to develop an AI model to detect cyberbullying lauguage. In this lab, we will keep learning how AI can be developed to detect cyberbullying. We will use a publicly available test dataset of cyberbullying images, and deploy an pre-trained AI model to automatically detect cyberbullying images. \n",
        "Approach towards analysing the cyber bullying in images in a dataset, there are three steps: \n",
        "1. Understand and identify the factors related to cyberbullying in images. \n",
        "2. Deploy the pre-trained AI model.\n",
        "3. Examine the AI to detect cyberbulling images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR_dMOJ3HJ21"
      },
      "source": [
        "## Download the pre-trained model, test dataset and the dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuE3371lG783"
      },
      "source": [
        "First, we need to download the pre-trained model and the test dataset used in the lab. Just hit the 'play' button run the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er3ZmAJoRZcL"
      },
      "outputs": [],
      "source": [
        " # download the model and dataset\n",
        "!wget -O auxes_17.pt https://buffalo.box.com/shared/static/cjk39hq7prpwj2rkqz6lc2jr6q2h5shy.pt # model checkpoints\n",
        "!wget -O cyberbullying_data.zip https://github.com/cuadvancelab/materials/blob/main/lab2/cyberbullying_data.zip?raw=true # test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybkEIhE6B4Kx"
      },
      "outputs": [],
      "source": [
        "# unzip the test data\n",
        "%%capture\n",
        "!unzip \"/content/cyberbullying_data.zip\" -d \"/content\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytz-y70fHfqd"
      },
      "source": [
        "Let's import all our softwares dependencies in our iPython notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Co9BU-xoIBr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KehdlyFsoIPQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import gzip\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from skimage import io, transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leCI51YW7UfE"
      },
      "source": [
        "## Load datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH_eewicHqlb"
      },
      "source": [
        "Now, let's run the subsequent codes to load your data from a predefined\n",
        "class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CROpOz3boJup"
      },
      "outputs": [],
      "source": [
        "class PosesDataset(Dataset):\n",
        "\n",
        "  def __init__(self, root_dir, poses_dir, auxes_dir):\n",
        "\n",
        "    self.samples = []\n",
        "    self.root_dir = root_dir\n",
        "    self.poses_dir = poses_dir\n",
        "    self.auxes_dir = auxes_dir\n",
        "\n",
        "    for _, _, cb_images in os.walk(self.root_dir + 'cyberbullying'): break\n",
        "    for _, _, non_cb_images in os.walk(self.root_dir + 'non_cyberbullying'): break\n",
        "    for _, _, cb_poses in os.walk(self.poses_dir + 'cyberbullying'): break\n",
        "    for _, _, non_cb_poses in os.walk(self.poses_dir + 'non_cyberbullying'): break\n",
        "\n",
        "    for i in cb_images:\n",
        "      self.samples.append((self.root_dir + 'cyberbullying/' + i, self.poses_dir + 'cyberbullying/' + i, self.auxes_dir + 'cyberbullying/' + i, 1))  \n",
        "\n",
        "    for i in non_cb_images:\n",
        "      self.samples.append((self.root_dir + 'non_cyberbullying/' + i, self.poses_dir + 'non_cyberbullying/' + i, self.auxes_dir + 'non_cyberbullying/' + i, 0))\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.samples)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    img_name, pose_name, aux_name, label = self.samples[idx]\n",
        "    image = io.imread(img_name)\n",
        "\n",
        "    aux = pickle.load(open(aux_name + '.p', 'rb'))\n",
        "    aux = torch.tensor(aux)\n",
        "    \n",
        "    # drop the alpha channel for some images\n",
        "    if image.shape == (224, 224): \n",
        "      # handle grayscale images   \n",
        "      image = np.stack([image, image, image], axis=2)\n",
        "\n",
        "    if image.shape == (224, 224, 4):\n",
        "      image = image[:,:,:3]\n",
        "\n",
        "    image = image.transpose((2, 0, 1)) # C X H X W\n",
        "    pose = io.imread(pose_name)\n",
        "    if pose.shape != (224, 224):\n",
        "      pose = pose[:,:,0]\n",
        "    pose = np.expand_dims(pose, axis = 0)\n",
        "    image = np.concatenate((image, pose), axis = 0)\n",
        "    sample = {'image': torch.from_numpy(image.copy()).float() / 255, 'aux': aux, 'label': label}\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyJIDz2-oMLl"
      },
      "outputs": [],
      "source": [
        "valid_set = PosesDataset('cyberbullying_data/cyberbullying_data_splits_clean/test/', 'cyberbullying_data/cyberbullying_poses/test/', 'cyberbullying_data/cyberbullying_data_auxes/test/')\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size = 1, shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OX8Si28urch"
      },
      "source": [
        "## How to identify cyberbullying in images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title An example image\n",
        "# importing required libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "  \n",
        "# reading the image\n",
        "testImage = img.imread('/content/cyberbullying_data/cyberbullying_data_splits_clean/test/cyberbullying/7.s-s-unshaven-sad-ashamed-man-doing-loser-sign-hand-fingers-his-front-funny-depressed-face-expression-s-139158713.jpg')\n",
        "  \n",
        "# displaying the image\n",
        "plt.imshow(testImage)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "alF46qymwqjX"
      },
      "source": [
        "**5 FACTORS to measurement cyberbulling in images**\n",
        "- Body-pose\n",
        "- Facial Emotion\n",
        "- Object\n",
        "- Gesture\n",
        "- Social Factors\n",
        "\n",
        "<img src=\"https://github.com/cuadvancelab/materials/blob/main/lab2/factors.png?raw=true\" alt=\"drawing\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CthXohcl7YPN"
      },
      "source": [
        "\n",
        "\n",
        "- - - -\n",
        "**<font color='red'>QUESTION 1:</font>\n",
        "Do you think there are any other factors that could help us identify cyberbullying in images?**\n",
        "- - - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZlkxZuv3WN3"
      },
      "source": [
        "The follow table shows the analysis of cyberbulling factors in images. Higher value of cosine similarity indicates higher correlation.\n",
        "\n",
        "| Factor        | Attribute           |  Cyberbulling  |  Non-cyberbulling  |  Description  |\n",
        "| ------------- |:----------:|:-----:|:-----:| ------------- :|\n",
        "| Body-pose      | Front pose <br> Non-front pose | 0.86<br>0.50 | 0.53 <br> 0.84 | Pose of subject in image is towards the viewer |\n",
        "| Emotion      | Joy <br> Sorrow <br> Anger <br> Surprise | 0.34<br>0.02<br>0.09<br>0.07 | 0.25<br>0.02<br>0.04<br>0.05 | Facial emotion of subject in image|\n",
        "| Gesture      | Hand gesture <br> No hand gesture | 0.71<br>0.70 | 0.32 <br> 0.94 | Hand gesture made by subject in imager |\n",
        "| Object      | Threatening object <br> No threatening object | 0.33<br>0.94 | 0.06 <br> 0.99 | Threatening object present in image |\n",
        "| Social      | Anti-LGBT <br> Anti-black racism | 0.45<br>0.03 | 0.06 <br> 0.00 | Anti-LGBT symbols and anti-black racism in image |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAKtA3rj7c_s"
      },
      "source": [
        "\n",
        "\n",
        "- - - -\n",
        "**<font color='red'>QUESTION 2:</font>\n",
        "What can you observe from the above table?**\n",
        "- - - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA_fj0um-RyJ"
      },
      "source": [
        "## Load our pre-trained AI model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Es0wlW55AA7s"
      },
      "source": [
        "For our AI model, it will consider both the low level image features and the cyberbulling factors identified before together to make prediction.\n",
        "\n",
        "The AI model prediction process looks like the following figure.\n",
        "<img src=\"https://github.com/cuadvancelab/materials/blob/main/lab2/model.png?raw=true\" alt=\"drawing\" width=\"700\"/>\n",
        "\n",
        "In our AI model, we combine the low level image features with the cyberbulling factors identified before. We combine these features using feature fusion techniques.\n",
        "\n",
        "We use a pre-trained `CNN` model for image features  and use a multi-layer perceptron model `MLP` for the factors related features, and combine the feature vectors from both these models using late fusion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2ODneL4FQCw"
      },
      "source": [
        "\n",
        "\n",
        "- - - -\n",
        "**<font color='red'>QUESTION 3:</font>\n",
        "Do you remember the AI we used when detecting cyberbullying text? <br> Similar with the image factors, what is the factor which can help AI detect cyberbulling text?**\n",
        "- - - -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSoMmCwNIJ4R"
      },
      "outputs": [],
      "source": [
        "# load vgg16 pre-trained model\n",
        "orig = models.vgg16(pretrained = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH7zjEWzoV_6"
      },
      "outputs": [],
      "source": [
        "class CB(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CB, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(4, 3, 1)\n",
        "    self.f = nn.Sequential(*list(orig.features.children()))\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "    self.aux_classifier = nn.Sequential(\n",
        "      nn.Linear(25097, 1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(1024, 25088),\n",
        "      nn.ReLU()  \n",
        "    )   \n",
        "    self.classifier = nn.Sequential(*list(orig.classifier.children()))\n",
        "    self.classifier[-1] = nn.Linear(4096, 2)\n",
        "    self.sig = nn.Sigmoid()\n",
        " \n",
        "  def forward(self, x, aux):\n",
        "    x = self.conv1(x) \n",
        "    x = self.f(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1) \n",
        "    x = torch.cat((x, aux), dim = 1)\n",
        "    x = self.aux_classifier(x)\n",
        "    x = self.classifier(x)\n",
        "    x = self.sig(x) \n",
        "\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0uFHmzNH6P1"
      },
      "source": [
        "Let's use GPU to deploy our AI if it is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB-maxBGoOms"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YijTxNzIIgeO"
      },
      "source": [
        "Pass the pre-trained checkpoints to the VGG model so that you can have our pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJyl75SEoYAg"
      },
      "outputs": [],
      "source": [
        "model = torch.load(\"auxes_17.pt\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "running_loss = []\n",
        "correct, incorrect, total = 0., 0., 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OquLZfQh7sfr"
      },
      "source": [
        "## Generate the detection resuls for validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnK2dbcDJCKB"
      },
      "source": [
        "Now, it's time to evaulate the pre-trained model's capability with our test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rw8zw7ppoZTI"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  for i_v, data_v in enumerate(valid_loader):\n",
        "    x_valid, y_valid, aux_valid = data_v['image'], data_v['label'], data_v['aux']\n",
        "    x_valid, y_valid, aux_valid = x_valid.to(device), y_valid.to(device, dtype = torch.long), aux_valid.to(device, dtype = torch.float)\n",
        "    y_valid_ = model(x_valid, aux_valid)\n",
        "    running_loss.append(criterion(y_valid_, y_valid))\n",
        "    _, predicted = torch.max(y_valid_.data, 1)\n",
        "    total += y_valid.size(0)\n",
        "    correct += (predicted == y_valid).sum().item() \n",
        "\n",
        "print('Val loss is: {:.3f}'.format((sum(running_loss) / len(running_loss)).item()))\n",
        "print('The accuracy for validation dataset is: {}%'.format((correct / total) * 100))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- - - -\n",
        "**<font color='red'>QUESTION 4:</font>\n",
        "How well does your model perform, and what is the accuracy of the validation dataset?**\n",
        "- - - -"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In Machine Learning, besides Accuracy (# Correct prediction / # Total prediction), we have different metrics for evaluating results, such as <br>\n",
        "\n",
        "**True Positive (TP):**<br>\n",
        "A true positive is an outcome where the model correctly predicts the positive class (labeled as cyberbullying).\n",
        "\n",
        "**True Negative (TN):**<br>\n",
        "A true negative is an outcome where the model correctly predicts the negative class (labeled as non-cyberbullying).\n",
        "\n",
        "**False Positive (FP):**<br>\n",
        "A false positive is an outcome where the model incorrectly predicts the positive class.\n",
        "\n",
        "**False Negative (FN):**<br>\n",
        "And a false negative is an outcome where the model incorrectly predicts the negative class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get TP, TN, FP, FN for the validation set\n",
        "TP, TN, FP, FN = 0, 0, 0, 0\n",
        "with torch.no_grad():\n",
        "    for i_v, data_v in enumerate(valid_loader):\n",
        "        x_valid, y_valid, aux_valid = data_v['image'], data_v['label'], data_v['aux']\n",
        "        x_valid, y_valid, aux_valid = x_valid.to(device), y_valid.to(device, dtype = torch.long), aux_valid.to(device, dtype = torch.float)\n",
        "        y_valid_ = model(x_valid, aux_valid)\n",
        "        _, predicted = torch.max(y_valid_.data, 1)\n",
        "        if y_valid == 1 and predicted == 1:\n",
        "            TP += 1\n",
        "        elif y_valid == 0 and predicted == 0:\n",
        "            TN += 1\n",
        "        elif y_valid == 0 and predicted == 1:\n",
        "            FP += 1\n",
        "        elif y_valid == 1 and predicted == 0:\n",
        "            FN += 1\n",
        "\n",
        "print('We have {} testing samples. Among them we have:'.format(len(valid_loader)))        \n",
        "print('True Positives: {}, True Negatives: {}, False Positives: {}, False Negatives: {}'.format(TP, TN, FP, FN))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- - - -\n",
        "**<font color='red'>QUESTION 5:</font>\n",
        "Can you interpret False Positives for cyberbullying detection tasks? Is it meaningful to discuss false-positive samples? Why?**\n",
        "- - - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWI-fdPuBjeL"
      },
      "source": [
        "### Let's check with one instance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvZeIcxYJPgu"
      },
      "source": [
        "To better understand the performance, let us visualize one instance in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCOsFqEmCjhl"
      },
      "outputs": [],
      "source": [
        "# check how many test data samples we have\n",
        "print(f\"we have {len(valid_set)} samples in our test dataset, you can choose any of them to see the prediction.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHZyh0FbDzzo"
      },
      "source": [
        "You can simply change the number in next cell to select different sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eE0MVD6RDeZh"
      },
      "outputs": [],
      "source": [
        "#@markdown Select a number to view the image and its label.\n",
        "\n",
        "picture_index  = \"5\" #@param [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
        "index = int(picture_index)\n",
        "instance = valid_set[index]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "img = mpimg.imread(valid_set.samples[index][0])\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "annot_label = \"cyberbullying\" if valid_set[index]['label']==1 else \"non-cyberbullying\"\n",
        "print('')\n",
        "print(\"The label of this image is: {}\".format(annot_label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt5bRKBbJx27"
      },
      "source": [
        "Run the following code cell to check the AI's prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfeLR_pB_pb5"
      },
      "outputs": [],
      "source": [
        "# from numpy.ma.core import outerproduct\n",
        "# check if the prediction is correct\n",
        "instance_image, instance_label, instance_aux = instance['image'].to(device), torch.tensor(instance['label']).to(device, dtype = torch.long), instance['aux'].to(device, dtype = torch.float)\n",
        "\n",
        "output = model(instance_image.unsqueeze(0), instance_aux.unsqueeze(0)).data\n",
        "_, prediction = torch.max(output.data, 1)\n",
        "predict_label = \"cyberbullying\" if prediction.item()==1 else \"non-cyberbullying\"\n",
        "comparision = \"correct\" if prediction==instance_label else \"not correct\"\n",
        "\n",
        "print(\"The AI prediction for this image is: {}, which is {}!\".format(annot_label, comparision))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLTkvWM_E_Id"
      },
      "source": [
        "## Discussion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-JK5h_ZJFDDH"
      },
      "source": [
        "\n",
        "\n",
        "- - - -\n",
        "**<font color='red'>QUESTION 6:</font>\n",
        "According to lab1 and lab2, what do think about the AIs? Are there other real-world problems that could benefit from artificial intelligence?**\n",
        "- - - -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYw2wtTyMiND"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
